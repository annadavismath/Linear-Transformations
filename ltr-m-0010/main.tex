\documentclass{ximera}


\author{Anna Davis \and Paul Zachlin} \title{Introduction to Linear Transformations} \license{CC-BY 4.0}

\renewcommand{\vec}[1]{{\bf #1}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\dfn}{\textit}
\newcommand{\dotp}{\cdot}
\newcommand{\id}{\text{id}}
 
\newtheorem{general}{Generalization}
\newtheorem{initprob}{Exploration Problem}
\usepackage{tikz-cd}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\pgfplotsset{compat=1.14}

\begin{document}

\begin{abstract}
  We give the definition of a linear transformation from $\RR^n$ into $\RR^m$ and use the definition to determine whether a given transformation is linear.
\end{abstract}
\maketitle



\section*{Linear Transformations}
We start by reviewing the definition of a function.

\begin{definition} 
  
Let $V$ and $W$ be sets.  A {\it function} $f$ from $V$ into $W$, denoted by 
$$f:V\rightarrow W$$
assigns to each element $x$ of $V$, an element $y=f(x)$ of $W$. 
\vskip 10pt
The set $V$ is called the {\it domain} of $f$, and the set $W$ is called the {\it codomain}.
\vskip 10pt
If $y=f(x)$, we say that $x$ {\it maps to} $y$, and $y$ is the {\it image} of $x$.
\vskip 10pt
The collection of images of all points of $V$ is called the {\it range} of $f$.  More often, we will refer to the range as the {\it image} of $V$ or the {\it image} of $f$.
  
\end{definition}


In algebra and calculus you worked with functions $f:\RR\rightarrow\RR$ whose domain and codomain were each the set of all real numbers.  In linear algebra, we call our functions {\it transformations}.  The domain and codomain of a transformation are vector spaces.  A typical transformation $T$ will map vectors of $\RR^n$ into $\RR^m$.

\begin{initprob}\label{init:lintransintro} In this exercise we will introduce a very special type of transformation by contrasting the effects of two transformations on vectors of $\RR^2$.  We will see that some transformations have ``nice" properties, while others do not.  Define $T_1$ and $T_2$ as follows:
$$T_1:\RR^2\rightarrow\RR^2$$
$$T_1\left(\begin{bmatrix}
x\\
y
\end{bmatrix}\right)=\begin{bmatrix}
x-y\\
x
\end{bmatrix}$$
$$T_2:\RR^2\rightarrow\RR^2$$
$$T_2\left(\begin{bmatrix}
x\\
y
\end{bmatrix}\right)=\begin{bmatrix}
-x+y+1\\
y-2
\end{bmatrix}$$

Each of these transformations takes a vector in $\RR^2$, and {\it{transforms}} it to another vector in $\RR^2$.  To see if you understand how these transformations are defined, see if you can determine what these transformations do to the vector $\begin{bmatrix}
4\\
3
\end{bmatrix}$. 

$$
T_1\left(\begin{bmatrix}
4\\
3
\end{bmatrix}\right)=\begin{bmatrix}
\answer{1}\\
\answer{4}
\end{bmatrix} \quad \text{and} \quad
T_2\left(\begin{bmatrix}
4\\
3
\end{bmatrix}\right)=\begin{bmatrix}
\answer{0}\\
\answer{1}\end{bmatrix}.$$

If you did not get correct answers, watch Video \ref{computation}



Now, let's take the vector $\begin{bmatrix}
4\\
3
\end{bmatrix}$ and multiply it by a scalar, say $7$.
$$7\begin{bmatrix}
4\\
3
\end{bmatrix} = \begin{bmatrix}
28\\
21
\end{bmatrix}$$.  

If we apply $T_1$ and $T_2$ to this product, we will see that $T_1$ ``handles it better" than $T_2$.  We compute:

$$
T_1\left(7\begin{bmatrix}
4\\
3
\end{bmatrix}\right)=T_1\left(\begin{bmatrix}
28\\
21
\end{bmatrix}\right)=\begin{bmatrix}
7\\
28
\end{bmatrix} \quad \text{and} \quad
T_2\left(7\begin{bmatrix}
4\\
3
\end{bmatrix}\right)=T_2\left(\begin{bmatrix}
28\\
21
\end{bmatrix}\right)=\begin{bmatrix}
-6\\
19\end{bmatrix}$$

For transformation $T_1$ we observe that multiplying the original vector by 7 has the effect of multiplying the image of that vector by 7.  In other words,

$$
T_1\left(7\begin{bmatrix}
4\\
3
\end{bmatrix}\right)=\begin{bmatrix}
7\\
28
\end{bmatrix}=7\begin{bmatrix}
1\\
4
\end{bmatrix}=7T_1\left(\begin{bmatrix}
4\\
3
\end{bmatrix}\right)$$

You should try to verify that this property does not hold for transformation $T_2$.  If you are not sure how to do this, watch Video \ref{computation2}.



There is nothing special about the number 7, and it is not hard to prove that for any scalar $k$ and vector $\vec{u}$ of $\RR^2$, $T_1$ satisfies
\begin{align}\label{lin1} kT_1(\vec{u})= T_1(k\vec{u}).\end{align}

In addition, $T_1$ satisfies another important property. For all vectors $\vec{u}$ and $\vec{v}$ of $\RR^2$ we have:
\begin{align}\label{lin2} T_1(\vec{u}+\vec{v}) = T_1(\vec{u})+T_1(\vec{v})\end{align}
We leave it to the reader to illustrate this property with a specific example (see Practice Problem \ref{prob:sum}), and show that $T_1$ satisfies (\ref{lin2}) in general.

Let $\vec{u}=\begin{bmatrix}
u_1\\
u_2
\end{bmatrix}$ and $\vec{v}=\begin{bmatrix}
v_1\\
v_2
\end{bmatrix}$, then
\begin{align*}
T_1(\vec{u}+\vec{v})&=T_1\left(\begin{bmatrix}
u_1\\
u_2
\end{bmatrix}+\begin{bmatrix}
v_1\\
v_2
\end{bmatrix}\right)=T_1\left(\begin{bmatrix}
u_1+v_1\\
u_2+v_2
\end{bmatrix}\right)=\begin{bmatrix}
u_1+v_1-u_2-v_2\\
u_1+v_1
\end{bmatrix}\\
&=\begin{bmatrix}
u_1-u_2\\
u_1
\end{bmatrix}+\begin{bmatrix}
v_1-v_2\\
v_1
\end{bmatrix}=T_1\left(\begin{bmatrix}
u_1\\
u_2
\end{bmatrix}\right)+T_1\left(\begin{bmatrix}
v_1\\
v_2
\end{bmatrix}\right)\\
&=T_1(\vec{u})+T_1(\vec{v})
\end{align*}
It turns out that $T_2$ fails to satisfy this condition.  
Can you prove that this is the case?  Remember that to prove that a property DOES NOT hold, it suffices to come up with a counter-example.  See if you can find vectors $\vec{u}$ and $\vec{v}$ such that 
\begin{align}\label{t2}T_2(\vec{u}+\vec{v}) \neq T_2(\vec{u})+T_2(\vec{v}).\end{align}
(See Practice Problem \ref{prob:prob2}.) 

Transformations like $T_1$ belong to a special category of transformations called {\it linear transformations}.
\end{initprob}

  \begin{definition} \label{def:lin}
  
A transformation $T:\RR^n\rightarrow \RR^m$ is called a {\it linear transformation} if the following are true for all vectors $\vec{u}$ and $\vec{v}$ in $\RR^n$, and scalars $k$.
\begin{equation}\label{eq:lintrans1}
T(k\vec{u})= kT(\vec{u})
\end{equation}
\begin{equation}\label{eq:lintrans2}
T(\vec{u}+\vec{v})= T(\vec{u})+T(\vec{v})
\end{equation}
  
\end{definition}


Properties (\ref{eq:lintrans1}) and (\ref{eq:lintrans2}) are often combined into a single property.


  
\begin{equation*}
T(k_1\vec{u}+k_2\vec{v})= k_1T(\vec{u})+k_2T(\vec{v})
\end{equation*}
  
\begin{example}\label{ex:lineartrans1}
Suppose $T:\RR^2\rightarrow\RR^2$ is a transformation such that 
$$T\left(\begin{bmatrix}
2\\
1
\end{bmatrix}\right)=\begin{bmatrix}
3\\
2
\end{bmatrix},\,\,\,T\left(\begin{bmatrix}
-1\\
0
\end{bmatrix}\right)=\begin{bmatrix}
1\\
1
\end{bmatrix},\,\,\,T\left(\begin{bmatrix}
-1\\
1
\end{bmatrix}\right)=\begin{bmatrix}
2\\
-4
\end{bmatrix}$$
Determine whether $T$ is a linear transformation.


\begin{explanation} Observe that
$$\begin{bmatrix}
-1\\
1
\end{bmatrix}=\begin{bmatrix}
2\\
1
\end{bmatrix}+3\begin{bmatrix}
-1\\
0
\end{bmatrix}$$
If $T$ were a linear transformation, then $$T\left(\begin{bmatrix}
-1\\
1
\end{bmatrix}\right)=T\left(\begin{bmatrix}
2\\
1
\end{bmatrix}+3\begin{bmatrix}
-1\\
0
\end{bmatrix}\right)=\begin{bmatrix}
3\\
2
\end{bmatrix}+3\begin{bmatrix}
1\\
1
\end{bmatrix}=\begin{bmatrix}
6\\
5
\end{bmatrix}$$
But according to the given,
$$T\left(\begin{bmatrix}-1\\1\end{bmatrix}\right)=\begin{bmatrix}2\\-4\end{bmatrix}$$
Since $\begin{bmatrix}
6\\
5
\end{bmatrix}\neq \begin{bmatrix}
2\\
-4
\end{bmatrix}$
we conclude that transformation $T$ is not linear.
\end{explanation}
\end{example}
  
  
  
In Exploration Problem \ref{init:lintransintro} we introduced a transformation $T_2$ which turned out to be non-linear.  It took some work to show that $T_2$ is not linear.  The following theorem would have made our work easier.

\begin{theorem}\label{th:zerotozero} Let $T:\RR^n\rightarrow \RR^m$ be a linear transformation.  Then $T(\vec{0})=\vec{0}$.  In other words, linear transformations map the zero vector to the zero vector.
\end{theorem}
\begin{proof}
Let $\vec{v}$ be any vector in $\RR^n$.  By linearity of $T$, we have:
$$T(\vec{0})=T(\vec{v}-\vec{v})=T(\vec{v})-T(\vec{v})=\vec{0}$$
\end{proof}

\begin{example}\label{ex:zerotozero}
Use Theorem \ref{th:zerotozero} to show that transformation $T_2$ of Exploration Problem \ref{init:lintransintro} is not linear.
\begin{explanation}
Recall that $T_2:\RR^2\rightarrow\RR^2$ was defined by
$$T_2\left(\begin{bmatrix}
x\\
y
\end{bmatrix}\right)=\begin{bmatrix}
-x+y+1\\
y-2
\end{bmatrix}$$
We evaluate $T_2$ at $\vec{0}$:
$$T_2(\vec{0})=\begin{bmatrix}
-0+0+1\\
0-2
\end{bmatrix}=\begin{bmatrix}1\\-2\end{bmatrix}\neq\vec{0}$$
Because $T_2(\vec{0})\neq\vec{0}$, we conclude that $T_2$ is not linear.
\end{explanation}
\end{example}


We conclude this section by introducing two simple but important transformations.

\begin{definition}\label{def:idtrans}
The identity transformation on $V$, denoted by $\id_V$, is a transformation that maps each element of the domain to itself.

In other words,
$$\id_{V}:V\rightarrow V$$ is a transformation such that $$\id_{V}(\vec{v})=\vec{v}\quad\text{for all}\quad \vec{v} \in V$$
\end{definition}

\begin{definition}\label{def:zerotrans}
The zero transformation, $Z$, maps every element of the domain to zero.

In other words,
$$Z:V\rightarrow W$$ is a transformation such that $$Z(\vec{v})=\vec{0}\quad\text{for all}\quad \vec{v} \in V$$
\end{definition}

\begin{theorem}\label{th:idlintrans}
The identity transformation is linear.
\end{theorem}
\begin{proof}
Left to the reader. (See Practice Problem \ref{prob:idtrans})
\end{proof}

\begin{theorem}\label{th:zerolintrans}
The zero transformation is linear.
\end{theorem}
\begin{proof}
Left to the reader.  (See Practice Problem \ref{prob:zerotrans})
\end{proof}

\section*{Linear Transformations Induced by Matrices}

\begin{initprob}\label{init:matrixtrans}   Let $$A=\begin{bmatrix}
3&-2&1\\
1&0&2
\end{bmatrix}$$
Let $\vec{v}$ be a vector in $\RR^3$.  Then $A\vec{v}$ is a vector in $\RR^2$.  We can use this observation to define a transformation $T:\RR^3\rightarrow\RR^2$ by $T(\vec{v})=A\vec{v}$.  For example,
$$T\left(\begin{bmatrix}
2\\
1\\
-3
\end{bmatrix}\right)=\begin{bmatrix}
3&-2&1\\
1&0&2
\end{bmatrix}\begin{bmatrix}
2\\
1\\
-3
\end{bmatrix}=\begin{bmatrix}
1\\
-4
\end{bmatrix}$$

\end{initprob}



We say that the transformation $T$ in Exploration Problem \ref{init:matrixtrans} is \dfn{induced} by matrix $A$.  Such transformations are often called \dfn{matrix transformations}.  In general, an $m\times n$ matrix induces a transformation from $\RR^n$ into $\RR^m$.  We will see that all matrix transformations are linear.


  \begin{theorem}\label{th:matrixtran} Let $A$ be an $m\times n$ matrix.  Define $T:\RR^n\rightarrow\RR^m$ by $T(\vec{v})=A\vec{v}$.  Then $T$ is a linear transformation.
\end{theorem}

\begin{proof}  Let $\vec{u}$ and $\vec{v}$ be vectors in $\RR^n$, and let $k$ be a scalar.  By properties of matrix multiplication we have:
$$T(\vec{u}+\vec{v})=A(\vec{u}+\vec{v})=A\vec{u}+A\vec{v}=T(\vec{u})+T(\vec{v})$$
$$T(k\vec{u})=A(k\vec{u})=kA\vec{u}=kT(\vec{u})$$
Therefore $T$ is a linear transformation.
\end{proof}

\begin{example}\label{ex:lineartrans2}
Let $T$ be a linear transformation induced by $$A=\begin{bmatrix}
2&0\\
1&4\\
0&1
\end{bmatrix}$$
\begin{enumerate}
\item \label{item:exlineartrans2a}
Find the domain and the codomain of $T$.
\item \label{item:exlineartrans2b}
Find $T\left(\begin{bmatrix}
-1\\
3
\end{bmatrix}\right)$ and $T\left(\begin{bmatrix}
2\\
-5
\end{bmatrix}\right)$

\item \label{item:exlineartrans2c}
Find the images of vectors ${\bf i}$ and ${\bf j}$.
\item \label{item:exlineartrans2d}
Find the image of $T$.
\end{enumerate}

\begin{explanation}
\ref{item:exlineartrans2a} $A$ is a $3\times 2$ matrix, so for the expression $T(\vec{x})=A\vec{x}$ to make sense, $\vec{x}$ has to be a $2\times 1$ vector.  Thus, the domain of $T$ is $\RR^2$.  The product $A\vec{x}$ is a $3\times 1$ vector.  So, the codomain of $T$ is $\RR^3$.

\ref{item:exlineartrans2b} $$T\left(\begin{bmatrix}-1\\3\end{bmatrix}\right)=\begin{bmatrix}
2&0\\
1&4\\
0&1
\end{bmatrix}\begin{bmatrix}-1\\3\end{bmatrix}=\begin{bmatrix}-2\\11\\3\end{bmatrix}$$
$$T\left(\begin{bmatrix}2\\-5\end{bmatrix}\right)=\begin{bmatrix}
2&0\\
1&4\\
0&1
\end{bmatrix}\begin{bmatrix}2\\-5\end{bmatrix}=\begin{bmatrix}4\\-18\\-5\end{bmatrix}$$

\ref{item:exlineartrans2c}
$$T(\vec{i})=T\left(\begin{bmatrix}1\\0\end{bmatrix}\right)=\begin{bmatrix}
2&0\\
1&4\\
0&1
\end{bmatrix}\begin{bmatrix}1\\0\end{bmatrix}=\begin{bmatrix}2\\1\\0\end{bmatrix}$$

$$T(\vec{j})=T\left(\begin{bmatrix}0\\1\end{bmatrix}\right)=\begin{bmatrix}
2&0\\
1&4\\
0&1
\end{bmatrix}\begin{bmatrix}0\\1\end{bmatrix}=\begin{bmatrix}0\\4\\1\end{bmatrix}$$
Observe that the image of $\vec{i}$ is the first column of $A$, and the image of $\vec{j}$ is the second column of $A$.  If you look at the mechanics of how this happened, you will realize that this is not a coincidence.  We will see this phenomenon again.

\ref{item:exlineartrans2d}  The image of $T$ consists of images of all individual vectors in $\RR^2$ under $T$.  A vector $\vec{v}$  in $\RR^2$ can be written as $\vec{v}=a\vec{i}+b\vec{j}$ for some real numbers  $a$ and $b$.  Consider the image of $\vec{v}$
$$T(\vec{v})=T(a\vec{i}+b\vec{j})=aT(\vec{i})+bT(\vec{j})=a\begin{bmatrix}2\\1\\0\end{bmatrix}+b\begin{bmatrix}0\\4\\1\end{bmatrix}$$
This shows that the range, or the image, of $T$ consists of all linear combinations of the columns of $A$.  In other words, the image of $T$ is the span of vectors $\begin{bmatrix}2\\1\\0\end{bmatrix}$ and $\begin{bmatrix}0\\4\\1\end{bmatrix}$. The two vectors are not scalar multiples of each other, therefore they span a plane in $\RR^3$.
\end{explanation}  
\end{example}
 


\begin{example}\label{ex:lineartrans3}
Let $$A=\begin{bmatrix}
-2&1&3\\
4&-2&-6
\end{bmatrix}$$
\begin{enumerate}
\item\label{item:lintrans3a}
Find the domain and the codomain of the the transformation $T$ induced by $A$.  
\item\label{item:lintrans3b}
Find and draw the image of $T$.
\end{enumerate}
\begin{explanation}
\ref{item:lintrans3a} $A$ is a $2\times 3$ matrix.  So, the domain of $T$ is $\RR^3$ and the codomain is $\RR^2$.

\ref{item:lintrans3b} To find the image of $T$, we will take a slightly different approach from what we did in Example \ref{ex:lineartrans2}\ref{item:exlineartrans2d}.

Let $\vec{v}=\begin{bmatrix}a\\b\\c\end{bmatrix}$ be an arbitrary vector of $\RR^3$.
The image of $\vec{v}$ is given by
\begin{align*}T(\vec{v})=\begin{bmatrix}
-2&1&3\\
4&-2&-6
\end{bmatrix}\begin{bmatrix}a\\b\\c\end{bmatrix}&=a\begin{bmatrix}-2\\4\end{bmatrix}+b\begin{bmatrix}1\\-2\end{bmatrix}+c\begin{bmatrix}3\\-6\end{bmatrix}\\
&=(a(-2)+b+c(3))\begin{bmatrix}1\\-2\end{bmatrix}
\end{align*}

This shows that the image of every vector in $\RR^3$ is a scalar multiple of $\begin{bmatrix}1\\-2\end{bmatrix}$.  This means that the image of $T$ is a line in $\RR^2$.

\begin{image}[3in]
\begin{tikzpicture}[scale=.7]

  \draw[->] (0,0)--(3,0);
  \draw[->] (0,0)--(0,3);
  \draw[->] (0,0)--(-1.5,-1);

  
  \draw[<->] (4,2)--(8,2);
  \draw[<->] (5,-1)--(5,3);
  \draw[line width=2pt,blue](4.5,3)--(6.5,-1) node[above=5mm, right=-1mm]{Image of $T$};
  
  \draw [->,line width=1pt,-stealth]  (2,-1) to[out=-60, in=240] (4.5, -1)node[above=-8mm, left=5mm]{$T$};
 % to[out=-20,in=-70] original command

\end{tikzpicture}
\end{image}
\end{explanation}
\end{example}





\section*{Practice Problems}
\begin{problem}\label{prob:sum}

Show that (\ref{lin2}) of Exploration Problem \ref{init:lintransintro} holds for vectors $\begin{bmatrix}3\\4\end{bmatrix}$ and $\begin{bmatrix}-2\\1\end{bmatrix}$.
\end{problem}

\begin{problem}\label{prob:prob2}
Use a counter-example to prove (\ref{t2}) of Exploration Problem \ref{init:lintransintro}.
\end{problem}

\begin{problem}\label{prob:imageoflincomb}
Suppose $T:\RR^{10}\rightarrow\RR^2$ is a linear transformation such that $T(\vec{u})=\begin{bmatrix}2\\-1\end{bmatrix}$ and $T(\vec{v})=\begin{bmatrix}-5\\3\end{bmatrix}$.  Find the image of $3\vec{u}-\vec{v}$.
\end{problem}


\begin{problem}\label{prob:notlinear} (Adopted from Kuttler, Exercise 5.1.3)
Let $\vec{u}$ be a fixed vector.  Define $T_{\vec{u}}:\RR^2\rightarrow\RR^2$, by $T_{\vec{u}}(\vec{x})=\vec{u}+\vec{x}$.
  \begin{enumerate}
  \item 
  Describe the effect of this transformation by sketching ${\bf x}$ and $T_{\vec{u}}({\bf x})$ for at least four vectors ${\bf x}$ and a fixed vector $\vec{u}$ of your choice.
  \item 
  Is $T_{\vec{u}}$ a linear transformation?
  \end{enumerate}
\end{problem}

\begin{problem}\label{prob:projectiontrans}
Define $P_{xy}:\RR^3\rightarrow\RR^2$, by $P_{xy}\left(\begin{bmatrix}
x\\
y\\
z
\end{bmatrix} \right)=\begin{bmatrix}
x\\
y\\
0
\end{bmatrix}$.  This transformation is called an {\it{orthogonal projection}} onto the $xy$-plane.  Show that $P_{xy}$ is a linear transformation.
\end{problem}

\begin{problem}\label{prob:imagesofijk}
Suppose a linear transformation $T:\RR^3\rightarrow\RR^3$ maps ${\bf i}$ to $\begin{bmatrix}2\\-1\\0\end{bmatrix}$, ${\bf j}$ to $\begin{bmatrix}-2\\4\\1\end{bmatrix}$, and ${\bf k}$ to $\begin{bmatrix}3\\0\\-5\end{bmatrix}$.  Find the image of $\begin{bmatrix}1\\1\\-2\end{bmatrix}$ under $T$.

$$T\left(\begin{bmatrix}1\\1\\-2\end{bmatrix}\right)=\begin{bmatrix}\answer{-6}\\\answer{3}\\\answer{11}\end{bmatrix}$$
\end{problem}

\begin{problem}\label{prob:idtrans} Prove Theorem \ref{th:idlintrans}\end{problem}

\begin{problem}\label{prob:zerotrans} Prove Theorem \ref{th:zerolintrans}\end{problem}

\begin{problem}\label{prob:domaincodomain}
For each matrix $A$ below, find the domain and the codomain of the linear transformation $T$ induced by $A$; find and draw the image of $T$. (Hint: See Example \ref{ex:lineartrans3}.)
  \begin{problem}\label{prob:domaincodomain1}
  $$A=\begin{bmatrix}0&0\\1&1\\2&0\end{bmatrix}$$
  \end{problem}
  \begin{problem}\label{prob:domaincodomain2}
  $$A=\begin{bmatrix}3&-1\\-3&1\end{bmatrix}$$
   \end{problem}
\end{problem}


\end{document} 